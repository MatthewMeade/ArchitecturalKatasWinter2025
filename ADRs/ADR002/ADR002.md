
# LLMs using grading context

## Context

The default LLM models do not carry sufficient context to help grade tests efficiently and effectively.

Therefore the LLM models will need to have a way of consuming this context and provide answers considering the consumed context.


## Decision

Use available LLMs, provide it relevant context using a RAG framework 

## Consequences

The AI grader will have sufficient context to effectively grade exams